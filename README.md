# Universal-Web-Monitoring-Agent
Dieses Repository enth√§lt einen KI-gesteuerten Browser-Agenten, der autonom Websites besucht, sich einloggt, Daten extrahiert und diese per E-Mail f√ºr die Weiterverarbeitung (z.B. durch CrewAI) versendet.


Hier ist ein Entwurf f√ºr eine professionelle README.md, die du direkt in dein GitHub-Repository legen kannst. Sie dient als "Gebrauchsanweisung" f√ºr dich, damit du auch in Zukunft sofort wei√üt, wie das System funktioniert und wie du es auf eine andere Website umstellst.
ü§ñ Universal Web Monitoring Agent
Dieses Repository enth√§lt einen KI-gesteuerten Browser-Agenten, der autonom Websites besucht, sich einloggt, Daten extrahiert und diese per E-Mail f√ºr die Weiterverarbeitung (z.B. durch CrewAI) versendet.
üöÄ Funktionsweise
 * GitHub Actions startet t√§glich (oder manuell) einen virtuellen Runner.
 * Der Agent verbindet sich mit dem Steel Browser (Cloud-Infrastruktur).
 * Das Groq LLM (Llama 3.3) steuert den Browser basierend auf generischen Anweisungen.
 * Die extrahierten Daten werden √ºber einen Gmail SMTP-Server mit einem sicheren App-Passwort versendet.
üõ† Einrichtung (Secrets)
Damit das System funktioniert, m√ºssen folgende Repository Secrets in GitHub angelegt werden (Settings > Secrets and variables > Actions):
| Secret | Beschreibung | Beispiel |
|---|---|---|
| TARGET_URL | Die Website, die √ºberwacht werden soll | https://example.com |
| TARGET_USER | Benutzername f√ºr den Login | dein_user |
| TARGET_PW | Passwort f√ºr den Login | dein_passwort |
| STEEL_API_KEY | API Key von steel.dev | steel-xxx |
| GROQ_API_KEY | API Key von console.groq.com | gsk-xxx |
| EMAIL_USER | Deine vollst√§ndige Gmail-Adresse | name@gmail.com |
| EMAIL_RECEIVER | Zieladresse f√ºr den Bericht | name@gmail.com |
| EMAIL_APP_PASSWORD | 16-stelliger Code von Google | abcdefghijklmnop |
üìÇ Dateien
 * agent.py: Das Hauptskript. Es ist webseiten-neutral programmiert.
 * .github/workflows/daily_run.yml: Die Automatisierungs-Logik f√ºr GitHub.
üîÑ Website wechseln
Um eine andere Website zu √ºberwachen, musst du keinen Code √§ndern. Passe einfach die TARGET_URL und die Login-Daten in den GitHub Secrets an. Die KI erkennt automatisch, wo sich die Login-Felder und Tabellen auf der neuen Seite befinden.
üìß Weiterverarbeitung (CrewAI)
Der Agent sendet E-Mails mit dem Betreff Neuer Datenbericht. Eine nachgelagerte CrewAI-Instanz kann diese Mails filtern:
 * Trigger: Suche nach Betreff "Neuer Datenbericht".
 * Action: Analysiere den Body, filtere √Ñnderungen heraus und speichere sie in der Datenbank.
Ein kleiner Tipp f√ºr die Zukunft:
Falls die neue Website, die du √ºberwachen willst, extrem komplex ist, kannst du im Code (agent.py) den task String noch um einen Satz erg√§nzen wie: "Suche speziell nach der Tabelle im Men√ºpunkt 'XYZ'". Aber f√ºr die meisten Foren und Portale wird der generische Befehl dank Llama 3.3 perfekt funktionieren.
Damit ist dein System komplett und zukunftssicher! Soll ich dir noch bei etwas anderem helfen?
